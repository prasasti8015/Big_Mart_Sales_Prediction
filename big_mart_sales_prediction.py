# -*- coding: utf-8 -*-
"""Big_Mart_Sales_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14PC4R_6aX0U859pqj8OwpOaTYeq6sr0B

## Import Libraries
"""

import numpy as np # linear algebra
import pandas as pd # data processing
import math
from matplotlib import pyplot as plt
import seaborn as sns

from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import mean_absolute_error , mean_squared_error , r2_score
from sklearn.model_selection import GridSearchCV
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
import optuna
# Ignore warnings ;)
import warnings
warnings.simplefilter("ignore")
# set seed for reproductibility
np.random.seed(0)

"""## Loading the Data"""

# loading the data
train = pd.read_csv("./train.csv")
test  = pd.read_csv( "./test.csv")

"""## Data Content"""

# lets start to look into train dataset
train.head()

train.shape

"""The train data set conatins 8523 rows and 12 columns"""

#check data and datatypes of the columns
train.info()

"""Item_Weight and Outlet_Size column contains null values"""

#check the statistical information of the test dataset
train.describe(include= 'all')

"""- There are 1559 unique items
- 5 types of Item Fat Content
- 16 types of items with Fruits and Vegetables being the most frequently bought item
- 10 different outlets
- 3 outlet size types with Medium type being the most common one
- 3 types of outlet location wih Tier 3 being the most frequent one
- 3 types of outlet with Supermarket type 1 being the most common
"""

#check for the number of nulls in each columns
train.isnull().sum()

"""There are null values in Item_Weight and Outlet_Size columns which we will need to impute"""

# lets investigate test dataset as well
test.head()

test.shape

test.info()

test.isnull().sum()

"""There are null values in the item_weight and Outlet_Size columns

## Exploratory Data Analysis

### Univarite analysis

#### Numerical Feature Analysis
"""

numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns.tolist()
numeric_cols

"""##### Distribution plot of the numerical features"""

fig, axes = plt.subplots(1, len(numeric_cols), figsize=(18, 4))
for ax, col in zip(axes, numeric_cols):
    sns.distplot(train[col].dropna(), ax=ax, bins=30, kde=True, hist=True)
    ax.set_title(f'Distribution of {col}')
    ax.set_xlabel(col)
    ax.set_ylabel('Density')
plt.tight_layout()
plt.show()

"""**Observation**
- The Item_Weight ranges from 5- 20 kg
- Item_Visibility has a right skewed distribution
- Most of the Item's MRP ranges from Rs 100 to 180
- Most of the outlets have been establised in the year of 1985, 1997 to 1999
- Item_Outlet_Sales is right skewed
"""

#plotting distribution for the test data
numeric_cols_test = test.select_dtypes(include=['float64', 'int64']).columns.tolist()
fig, axes = plt.subplots(1, len(numeric_cols_test), figsize=(18, 4))
for ax, col in zip(axes, numeric_cols_test):
    sns.distplot(test[col].dropna(), ax=ax, bins=30, kde=True, hist=True)
    ax.set_title(f'Distribution of {col}')
    ax.set_xlabel(col)
    ax.set_ylabel('Density')
plt.tight_layout()
plt.show()

"""##### Box Plot of the numerical Features"""

# Box plots for numerical features (side-by-side) of train data
fig, axes = plt.subplots(1, len(numeric_cols), figsize=(18, 5))
for ax, col in zip(axes, numeric_cols):
    sns.boxplot(y=train[col], ax=ax)
    ax.set_title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

# Box plots for numerical features (side-by-side) of test data
fig, axes = plt.subplots(1, len(numeric_cols_test), figsize=(18, 5))
for ax, col in zip(axes, numeric_cols_test):
    sns.boxplot(y=test[col], ax=ax)
    ax.set_title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""**Observations:**
- Item_Weight, Item_MRP and OutletEstablishment_Year has no outliers
- Item_Visibility and Item_Outlet_Sales has outliers in the data
- the distribution of data both in test and train are almost similar

#### Categorical Features
"""

categorical_features = train.select_dtypes(include=['object']).columns.tolist()
categorical_features

#check how the categories of each of the categorical features look like
for col in categorical_features:
    print(f"\nValue counts for {col}:")
    print(train[col].value_counts())
    print("="*50)

"""##### Feature Distributions"""

categorical_cols = ['Item_Fat_Content','Item_Type','Outlet_Size','Outlet_Location_Type','Outlet_Type']
# Set up the grid size dynamically based on number of features
n_cols = 3
n_rows = (len(categorical_cols) + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(24, 10))
axes = axes.flatten()  # Flatten for easy indexing

for i, col in enumerate(categorical_cols):
    sns.countplot(data=train, x=col, ax=axes[i], palette='tab20', order=train[col].value_counts().index)
    axes[i].set_title(f'Distribution of {col}', fontsize=12)
    axes[i].set_xlabel(col, fontsize=10)
    axes[i].set_ylabel('Count')
    axes[i].tick_params(axis='x', labelrotation=45)

# Remove any unused subplots
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Setup grid for side-by-side pie charts
n_cols = 3
n_rows = (len(categorical_cols) + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 10))
axes = axes.flatten()

for i, col in enumerate(categorical_cols):
    counts = train[col].value_counts()
    axes[i].pie(counts, labels=counts.index, autopct='%.2f', startangle=140, colors=sns.color_palette('tab20', n_colors=len(counts)), textprops={'fontsize': 6})
    axes[i].set_title(f'{col} Distribution')

# Hide unused subplots
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""**Observations:**
- Item_Fat_Content feature needs to be cleaned
  - LF, Low Fat and low fat should be made the same category "Low Fat"
  - reg and Regular should be mapped to same category "Regular"
- Outlet_Location_type can be encoded as per the tier number

### Bivariate Analysis
"""

# Scatter plots with hue
important_categoricals = ['Outlet_Type', 'Outlet_Location_Type', 'Outlet_Size', 'Item_Fat_Content']

for cat in important_categoricals:
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    for ax, num in zip(axes, ['Item_Weight', 'Item_Visibility', 'Item_MRP']):
        sns.scatterplot(x=train[num], y=train['Item_Outlet_Sales'], hue=train[cat], palette='Set2', alpha=0.7, ax=ax)
        ax.set_title(f'{num} vs Sales by {cat}')
    plt.tight_layout()
    plt.show()

# Pairplot with hue for a categorical feature (e.g., Outlet_Type)
sns.pairplot(train, vars=['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Outlet_Sales'], hue='Outlet_Type', palette='Set2')
plt.suptitle('Pairwise Relationships Colored by Outlet_Type', y=1.02)
plt.show()

sns.heatmap(train.drop(['Item_Identifier','Outlet_Identifier','Outlet_Type','Item_Type', 'Outlet_Location_Type', 'Outlet_Size', 'Item_Fat_Content'], axis=1).corr(), annot=True)

sns.barplot(data=train, x='Outlet_Size', y='Item_Outlet_Sales', palette='tab20')

sns.barplot(data=train, x='Outlet_Type', y='Item_Outlet_Sales', palette='tab20')

"""## Missing Values Treatment

It has been seen from the exploratory data analysis that Outlet_Type and Item_Weight has null values.
We can impute missing values in the following way:
- **Item_Weight** being a numerical column and since no outliers have been seen we can replace the missing values with mean.
- **Outlet_Type** being a categorical column, we can replace the missing values with mode value.
"""

# Impute Item_Weight with mean
train['Item_Weight'].fillna(train['Item_Weight'].mean(), inplace=True)
test['Item_Weight'].fillna(test['Item_Weight'].mean(), inplace=True)

# Impute Outlet_Size with mode
outlet_size_mode_train = train['Outlet_Size'].dropna().mode()[0]
outlet_size_mode_test = test['Outlet_Size'].dropna().mode()[0]

train['Outlet_Size'].fillna(outlet_size_mode_train, inplace=True)
test['Outlet_Size'].fillna(outlet_size_mode_test, inplace=True)

train.isnull().sum()

"""## Feature Engineering

### Capping of Outliers
"""

# Function to cap outliers using IQR
def cap_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[column] = np.where(df[column] < lower_bound, lower_bound,
                          np.where(df[column] > upper_bound, upper_bound, df[column]))

# Backup original columns for comparison
train_copy = train.copy()

# Before capping
fig, axes = plt.subplots(1, 2, figsize=(12, 5))
sns.boxplot(y=train_copy['Item_Visibility'], ax=axes[0])
axes[0].set_title('Before Capping: Item_Visibility')
sns.boxplot(y=train_copy['Item_Outlet_Sales'], ax=axes[1])
axes[1].set_title('Before Capping: Item_Outlet_Sales')
plt.tight_layout()
plt.show()

# Apply outlier capping
cap_outliers_iqr(train, 'Item_Visibility')
cap_outliers_iqr(train, 'Item_Outlet_Sales')

# After capping
fig, axes = plt.subplots(1, 2, figsize=(12, 5))
sns.boxplot(y=train['Item_Visibility'], ax=axes[0])
axes[0].set_title('After Capping: Item_Visibility')
sns.boxplot(y=train['Item_Outlet_Sales'], ax=axes[1])
axes[1].set_title('After Capping: Item_Outlet_Sales')
plt.tight_layout()
plt.show()

"""### Correcting Item_Fat_Content Column"""

# Let's correct the errors in the Item_Fat_Content column

train['Item_Fat_Content'] = train['Item_Fat_Content'].map({'Low Fat':'Low Fat','low fat':"Low Fat",'LF':"Low Fat",'Regular':'Regular','reg':"Regular"})

test['Item_Fat_Content'] = test['Item_Fat_Content'].map({'Low Fat':'Low Fat','low fat' :"Low Fat",'LF':"Low Fat",'Regular':'Regular','reg':"Regular"})

# sns.countplot(x=train['Item_Fat_Content'])
sns.countplot(data=train, x='Item_Fat_Content', palette='tab20', order=train['Item_Fat_Content'].value_counts().index)

"""### Creating Outlet Age"""

train['Outlet_Age'] = 2013 - train['Outlet_Establishment_Year']
test['Outlet_Age'] = 2013 - test['Outlet_Establishment_Year']

train = train.drop('Outlet_Establishment_Year', axis = 1)
test = test.drop('Outlet_Establishment_Year', axis = 1)

"""### Creating Broader category for Item _Identifier"""

# Extract broad category from Item_Identifier
train['Item_Category'] = train['Item_Identifier'].apply(lambda x: x[:2])
train['Item_Category'] = train['Item_Category'].map({'FD': 'Food', 'NC': 'Non-Consumable', 'DR': 'Drinks'})

test['Item_Category'] = test['Item_Identifier'].apply(lambda x: x[:2])
test['Item_Category'] = test['Item_Category'].map({'FD': 'Food', 'NC': 'Non-Consumable', 'DR': 'Drinks'})

# Mark Non-Consumables and set Fat_Content to 'Non-Edible'
train.loc[train['Item_Category'] == 'Non-Consumable', 'Item_Fat_Content'] = 'Non-Edible'
test.loc[test['Item_Category'] == 'Non-Consumable', 'Item_Fat_Content'] = 'Non-Edible'

sns.countplot(x=train['Item_Category'], palette='Set2')

"""### Label Encoding"""

test.isnull().sum()

train['Outlet_Size'] = train['Outlet_Size'].map({'Small'  : 1, 'Medium' : 2, 'High'   : 3}).astype(int)

test['Outlet_Size'] = test['Outlet_Size'].map({'Small'  : 1, 'Medium' : 2, 'High'   : 3}).astype(int)

sns.countplot(x=train['Outlet_Size'], palette='Set2')

# Outlet_Location_Type feature encoding by getting the last character and converting to int type

train['Outlet_Location_Type'] = train['Outlet_Location_Type'].str[-1:].astype(int)
test['Outlet_Location_Type']  = test['Outlet_Location_Type'].str[-1:].astype(int)
sns.countplot(x=train['Outlet_Location_Type'], palette='Set2')

train.head()

#Label Encoder for Ordinal Features

le = LabelEncoder()
ordinal_features = ['Item_Fat_Content', 'Outlet_Type', 'Outlet_Location_Type', 'Outlet_Size']

for feature in ordinal_features:
    train[feature] = le.fit_transform(train[feature])
    test[feature]  = le.fit_transform(test[feature])

# Save identifiers for final submission
test_ids = test[['Item_Identifier', 'Outlet_Identifier']].copy()

# One Hot Encoding for 'Item_Type', 'Item_Category', 'Outlet_Identifier' variable

train = pd.get_dummies(train, columns=['Item_Type', 'Item_Category', 'Outlet_Identifier'], drop_first=True, dtype=int)
test  = pd.get_dummies(test,  columns=['Item_Type', 'Item_Category', 'Outlet_Identifier'], drop_first=True, dtype=int)

train.head()

train.shape

"""## Model Building"""

train.drop(labels=['Item_Identifier'], axis=1, inplace=True)
test.drop(labels=['Item_Identifier'],  axis=1, inplace=True)

X = train.drop('Item_Outlet_Sales', axis=1)
y = train['Item_Outlet_Sales']

# Step 7: Train-Test Split and Feature Scaling
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_valid_scaled = scaler.transform(X_valid)
test_scaled = scaler.transform(test)

"""### Model Comparison"""

# Step 8: Model Comparison
models = {
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=0.2),
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
    'XGBoost': XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42),
    'LightGBM': LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)
}

rmse_scores = {}

for name, model in models.items():
    if name in ['LinearRegression', 'Ridge', 'Lasso']:
        model.fit(X_train_scaled, y_train)
        preds = model.predict(X_valid_scaled)
        train_score = model.score(X_train_scaled, y_train)
        test_score = model.score(X_valid_scaled, y_valid)
    else:
        model.fit(X_train, y_train)
        preds = model.predict(X_valid)
        train_score = model.score(X_train, y_train)
        test_score = model.score(X_valid, y_valid)

    rmse = np.sqrt(mean_squared_error(y_valid, preds))
    r2 = r2_score(y_valid, preds)
    rmse_scores[name] = rmse

    print(f"Training score of {name}  : {train_score:.4f}")
    print(f"Test score of {name}      : {test_score:.4f}")
    print(f"{name} RMSE: {rmse:.4f}")
    print(f"{name} R2 Score: {r2:.4f}")
    print("="*100)

"""**Observations:**
- Among Linear regression, ridge and Lasso Regression, Ridge and Lasso gives better result as it has lesser RMSE score
- Random forest seems to overfit with training score of 93% but test score of 57%
- Gradient Boosting performs the best with the lowest RMSE score of 972.53 among all

#### Hyper Parameter Tuning with Gradient Boosting model
"""

def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])
    }

    model = GradientBoostingRegressor(random_state=42, **params)
    score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)
    return -1.0 * score.mean()

# Create and optimize study
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=50, n_jobs=-1)

print("Best hyperparameters:", study.best_trial.params)

# Build model with best parameters from Optuna
best_params = study.best_trial.params
optuna_gb_model = GradientBoostingRegressor(random_state=42, **best_params)
optuna_gb_model.fit(X_train, y_train)

# Evaluation
gb_preds = optuna_gb_model.predict(X_valid)
rmse = np.sqrt(mean_squared_error(y_valid, gb_preds))
r2 = r2_score(y_valid, gb_preds)

print(f"Optuna-Tuned GradientBoosting RMSE: {rmse:.4f}")
print(f"Optuna-Tuned GradientBoosting R2: {r2:.4f}")

optuna_gb_model.fit(X, y)
final_predictions = optuna_gb_model.predict(test)
test_ids['Item_Outlet_Sales'] = final_predictions
submission = test_ids[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]
submission.to_csv("bigmart_submission_optuna.csv", index=False)
print("Optuna-tuned submission file created successfully.")

def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'max_depth': trial.suggest_int('max_depth', 3, 12),
        'num_leaves': trial.suggest_int('num_leaves', 20, 150),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'random_state': 42
    }

    model = LGBMRegressor(**params)
    model.fit(X_train, y_train)
    preds = model.predict(X_valid)
    rmse = np.sqrt(mean_squared_error(y_valid, preds))
    return rmse

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50, timeout=600)

print("Best LightGBM Parameters:", study.best_trial.params)

# Retrain with best params
best_lgbm = LGBMRegressor(**study.best_trial.params, random_state=42)
best_lgbm.fit(X, y)
final_preds_lgbm = best_lgbm.predict(test)
final_preds_lgbm = np.maximum(0, final_preds_lgbm)  # Prevent negative predictions

test_ids['Item_Outlet_Sales'] = final_preds_lgbm
submission_lgbm = test_ids[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]
submission_lgbm.to_csv("bigmart_submission_lightgbm_optuna.csv", index=False)
print("Submission file with Optuna-tuned LightGBM created successfully.")

